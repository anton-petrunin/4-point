\documentclass[a4paper,10pt]{article}
\usepackage{paper-en}
\usepackage{hyperref}

%\usepackage[notref,notcite,color]{showkeys}

\def\thetitle{Quadratic metric comparisons}
\def\theauthors{Nina Lebedeva, Anton Petrunin, and Vladimir Zolotov}

\hypersetup{colorlinks=true,
citecolor=black,
linkcolor=black,
anchorcolor=black,
filecolor=black,
menucolor=black,
urlcolor=black,
pdftitle={\thetitle},
pdfauthor={\theauthors}
}

%\usepackage[a-2b,mathxmp]{pdfx}[2018/12/22]
%\overfullrule=100mm
%\usepackage[none]{hyphenat}
\begin{document}
%\pagestyle{empty}\renewcommand\includegraphics[2][{}]{}

\title{\thetitle}
\author{\theauthors}
\date{}
\maketitle

\begin{abstract}
We study the effect on length-metric spaces imposed by quadratic inequalities on the six distances between points in every quadruple.
\end{abstract}

\section{Quadratic inequality}\label{par:quadratic-inq}

Let $\bm{x}\z=(x_1,\dots,x_n)$ be an $n$-point array in a metric space $X$ and let $a_{i,j}$ be components of a symmetric $n{\times}n$ matrix.
An inequality of the following type
\[\sum_{i,j}a_{i,j}\cdot|x_i-x_j|_X^2\ge 0\]
will be called \emph{quadratic}.
A system of quadratic inequalities will be called \emph{quadratic condition}.

We will be interested in length spaces $X$ such that a given quadratic condition holds for any $n$-point array in $X$.

\section{Outline}

\begin{thm}{Main theorem}
Suppose that a quadratic condition on 4-points satisfies the globalization property;
that is, if this condition holds locally (in a neighborhood of any point) in a length space $X$ then it holds in $X$.
Then either the condition is trivial, or it describes Alexandrov spaces with nonnegative curvature.
\end{thm}

This statement is proved in Section~\ref{par:globalization}.
It says that the Toponogov theorem has no simple relatives.
The rest of the paper has auxiliary nature.
We will state two results that have independent interest.
Their formulation use \emph{inequalities of negative type} --- a special case of quadratic inequalities with $a_{i,j}=-\lambda_i\cdot\lambda_j$ for a real array $(\lambda_1,\dots, \lambda_n)$ such that $\lambda_1+\dots+\lambda_n=0$; see Section~\ref{par:rank-one}.

In Section~\ref{Four-point arrays}, we prove the following version of a theorem of Abraham Wald \cite[§ 7]{wald} that describes the metrics of all possible 4-point arrays in Alexandrov spaces with nonnegative and nonpositive curvature.

\begin{thm}{Proposition}
The following three conditions are equivalent:
\begin{enumerate}[(i)]
\item A 4-point metric space $X$ is isometric to a subset of a length space with nonnegative (nonpositive) curvature in the sense of Alexandrov.
\item $X$ is isometric to a subset in the product of $\RR^3\times r\cdot \SSS^1$ for some $r>0$ (respectively, $\RR^3\times Y$, where $Y$ denotes the tripod; that is, three half-lines with a common base point)
\item All inequalities of negative type with $\lambda$-arrays such that $\lambda_1\cdot\lambda_2\cdot\lambda_3\cdot\lambda_4<0$ (respectively, type $\lambda_1\cdot\lambda_2\cdot\lambda_3\cdot\lambda_4>0$) hold in hold in $X$.
\end{enumerate}
\end{thm}

In Section~\ref{Alexandrov's comparison} we prove that a single nondegenerate inequality of negative type defines Alexandrov spaces with nonnegative and nonpositive curvature.

\begin{thm}{Proposition}
Let us consider all length spaces that satisfy the quadratic condition given by an inequality of negative type $\lambda$-array $(\lambda_1,\lambda_2,\lambda_3,\lambda_4)$.
\begin{enumerate}[(i)]
\item If $\lambda_1\cdot\lambda_2\cdot\lambda_3\cdot\lambda_4<0$, then it describes all Alexandrov spaces with nonnegative curvature.
\item If $\lambda_1\cdot\lambda_2\cdot\lambda_3\cdot\lambda_4>0$, then it describes all Alexandrov spaces with nonpositive curvature.
\item If $\lambda_1\cdot\lambda_2\cdot\lambda_3\cdot\lambda_4=0$, then it gives no restrictions; it describes all length spaces.
\end{enumerate}

\end{thm}

This statement shows that a relatively weak form of 4-point comparison  forces a much stronger 4-point comparison.
The proof is a straightforward combination of the arguments by Takashi Sato \cite{sato} and its variation by the first two authors \cite{lebedeva-petrunin-2010};
these papers consider particular cases
such inequalities, namely those for the $\lambda$-arrays $(1,1,-1,-1)$ and $(1,1,1,-3)$.

Sections \ref{Associated form} and \ref{par:rank-one} introduce necessary definitions.
Here we define the associated quadratic form for a point array and inequalities of negative type.
We also prove several basic statements that are valid for all $n$-point arrays.
Section \ref{Auxiliary statements} provides a technical statemet for the proof of the main theorem.

\section{Associated form}\label{Associated form}

Choose a point array $\bm{x}=(x_1,\dots,x_n)$ in a metric space.
Let $V_n\z=\RR^{n-1}$ be Euclidean space with a choice of unit-edge regular simplex $\triangle$, whose vertices are $y_1,\dots,y_n$.
Consider the quadratic form $\rho_{\bm{x}}$ on $V_n$ that is defined by the equalities
\[\rho_{\bm{x}}(y_i-y_j)=|x_i-x_j|^2_X\]
for all indices $i$ and $j$.

The quadratic form $\rho_{\bm{x}}$ will be called the \emph{associated form} of $\bm{x}=(x_1,\z\dots,x_n)$;
it is uniquely defined and remembers all distances $|x_i-x_j|_X$
(we assume that the simplex $\triangle$ in $V_n$ is known).
We may not distinguish between associated form $\rho_{\bm{x}}$ and corresponding semimetric on $\bm{x}=(x_1,\dots,x_n)$.

The Euclidean structure on $V_n$ identifies it with $V_n^*$.
The space of quadratic forms over $V_n$ will be denoted by $W_n$;
it is the symmetric square of $V_n=V_n^*$, and can be written as $W_n=S^2(V_n^*)=S^2(V_n)$.

Any quadratic inequality described above defines linear inequalities on $W_n$, so they can be written as $\langle\omega,\rho_{\bm{x}}\rangle\ge 0$ for a fixed $\omega\in W_n$.
Therefore, any quadratic  condition defines a closed convex cone in $W_n$, say $K$;
that is, $K$ is a nonempty closed set such that if $v,w\in K$, then $a\cdot v+b\cdot w\in K$ for any $a,b\ge0$.
Denote by $\mathcal{M}_K$ the class of all length spaces $X$ such that
$\rho_{\bm{x}}\in K$ for any $n$-point array $\bm{x}\z=(x_1,\dots,x_n)$ in~$X$.
The class $\mathcal{M}_K$ respects distance-preserving embeddings; that is,
if there is a distance-preserving embedding $X\to Y$ between length spaces and $Y \in  \mathcal{M}_K$, then $X\in \mathcal{M}_K$.

Since $K$ is a convex cone,
\[X,\ Y\in  \mathcal{M}_K
\qquad\Longrightarrow\qquad
X\times Y,\ a\cdot X\in\mathcal{M}_K
\]
for any $a\ge 0$;
here $X\times Y$ denotes the $\ell_2$-product of metric spaces, and
$a\cdot X$ denotes the rescaled copy of $X$ with factor $a$.

The last observation can be used in the opposite direction as well.
It gives that all forms $\rho_{\bm{x}}$ for point arrays $\bm{x}$ in $\mathcal{M}_K$-spaces form a convex cone, say $K'$.

Evidently $K'\subset K$, and this inclusion might be strict.
The first reason comes from the triangle inequality, which is equivalent to $\rho_{\bm{x}}(w)\ge 0$ for any vector $w$ in a 2-faces of $\triangle$.
These inequalities must hold for any form in $K'$.
Furthermore, if $\rho_{\bm{x}}\in K'$, then $\rho_{\hat{\bm{x}}}\in K'$ for any $n$-point array $\hat{\bm{x}}$ made from the points of $\bm{x}$; in particular $\hat{\bm{x}}$ might be a permutation of points in $\bm{x}$.

These two conditions hold for all metrics (not necessarily intrinsic),
and one cannot get more for general metric spaces.
The next observation already uses length-metricness.

\begin{thm}{Observation}
If $K$ is a closed convex cone in $W_n$, then $K'$ is closed.
Moreover, $\mathcal{M}_K$ is closed under ultralimits.
\end{thm}

(For \emph{ultralimits} and \emph{ultracompletions} of metric spaces and all related topics, see, for example, \cite{petrunin2023}.)

\parit{Proof.}
The last statement is evident, and it implies the first statement.

Indeed, for any sequence of spaces $X_n$ in $\mathcal{M}_K$, its ultralimit $X_\omega$ also belongs to $\mathcal{M}_K$.
Therefore, given a sequence of point arrays $\bm{x}_n$ in $X_n$,
its ultralimit $\bm{x}_\omega$ in $X_\omega$ has limit distances between corresponding points.
Hence, the result.
\qeds

\begin{thm}{Proposition}\label{prop:Associated form}
Let $K$ be a closed convex cone in $W_n$ such that $K=K'$.
If $K$ is nontrivial (that is, $K\ne \{0\}$), then $\mathcal{M}_K$ contains all Euclidean spaces.
\end{thm}

\parit{Proof.}
Since $K$ is nontrivial, $\mathcal{M}_K$ contains a space, say $X$, with two distinct points.
Consider the ultracompletion $X^\omega$ of $X$;
the space $X$ will be considered as a subset of $X^\omega$.
Since $K$ is closed, the observation implies that $X^\omega\in \mathcal{M}_K$.

Since  $X$ is a length space, $X^\omega$ has to be geodesic.
Since $X^\omega$
contains a pair of distinct points, it must contain a nontrivial geodesic.
It follows that $\mathcal{M}_K$ contains a line segment.
By rescaling the segment and passing to the ultralimit, we get $\RR\in \mathcal{M}_K$;
taking products of real lines then yields the result.
\qeds

Let us denote by $Q$ the cone of nonnegative quadratic forms in $W_n$.
Its dual cone $Q^*\subset W_n^*=S^2(V_n)$ is generated by tensor squares of vectors in~$V_n$.

\begin{thm}{Corollary}
Let $K$ be a closed convex cone in $W_n$ such that $K=K'$.
Then either $K\supset Q$ or $K$ is trivial; that is, $K=\{0\}$.
\end{thm}

\parit{Proof.}
Since $\RR\in \mathcal{M}_K$, we get that $\sigma^2\in K$ for any linear function $\sigma\:V_n\to\RR$.
By the spectral theorem, any form in $Q$ can be written as a sum of squares of linear functions, hence the result.
\qeds

\section{Rank-one inequalities}\label{par:rank-one}
Recall that $\rho_{\bm{x}}$ denotes the associated quadratic form for a given point array $\bm{x}=(x_1,\dots,x_n)$.

\begin{thm}{Observation}\label{obs:rank-one}
A given point array $\bm{x}=(x_1,\dots,x_n)$ is isometric to an array in a Euclidean space if and only if $\rho_{\bm{x}}(v)\ge 0$ for any vector $v$.
\end{thm}

An inequality of type $\rho_{\bm{x}}(v)\ge 0$ for a fixed vector $v\in V_n$ will be called \emph{rank-one} inequality.
It belongs to the class of quadratic inequalities.  
In the notation of Section~\ref{par:quadratic-inq}, it means that $a_{i,j}=-\lambda_i\cdot\lambda_j$ for a real array $(\lambda_1,\dots, \lambda_n)$ such that
$\lambda_1+\dots+\lambda_n=0$.
Such inequalities are also known as inequalities of \emph{negative type} \cite{deza-lauren}.
If the array $(\lambda_1,\dots, \lambda_n)$ contains $i$ positive and $j$ negative numbers,
then we say that this is an inequality of \emph{negative type} $(i,j)$.
Since changing the signs of all $\lambda_i$ does not change the inequality, we can always assume that $i\ge j$.

\section{Four-point arrays}\label{Four-point arrays}

For $4$-point arrays, we have two interesting types of rank-one inequalities: negative type $(2,2)$ and $(3,1)$.
The type $(1,1)$ is trivial, and
the type $(2,1)$ follows from the triangle inequality.
In fact, all the triangle inequalities (we have 12 of them for 4 points) are equivalent to all inequalities of negative type $(2,1)$ (which is an infinite set).

Consider a rank-one inequality $\rho_{\bm{x}}(v)\ge 0$; we may assume that $v$ is a unit vector.
Since the sign of $v$ does not change the inequality, we may assume that it lies in a closed hemisphere bounded by an equator in the direction of one of the facets of $\triangle$.
These equators divide the hemisphere into 8 triangles and 6 quadrangles.
The inequality $\rho_{\bm{x}}(v)\ge 0$ has negative type $(2,2)$ or $(3,1)$
if and only if $v$ lies in the interior of a triangle or a quadrangle, respectively.
Equivalently, this inequality is of negative type $(2,2)$ if $v$ points from one edge of the tetrahedron $\triangle$ to the opposite edge, and of type $(3,1)$ if $v$ points from a vertex to the opposite facet (up to the sign of $v$).

\begin{wrapfigure}{o}{36mm}
\centering
\vskip-3mm
\includegraphics{mppics/pic-20}
\vskip-0mm
\end{wrapfigure}

If a vector $v$ is parallel to a facet of $\triangle$, then $\rho_{\bm{x}}(v)\ge 0$ is an inequality of negative type $(2,1)$, which follows from the triangle inequality.
The picture shows the hemisphere.
The labels on the edges indicate which triangle inequality becomes an equality when $\rho_{\bm{x}}$ vanishes at a vector on that edge;
for example, the label $123$ means that
\[|x_1-x_2|+|x_2-x_3|=|x_1-x_3|.\]
If $\rho_{\bm{x}}$ vanishes on the intersection of equators, then two points in the array have to coincide;
the label shows which pair.
For example, if it is marked by $12$, then $x_1=x_2$.

\begin{thm}{Proposition}\label{prop:Four-point arrays}
Let $X$ be a 4-point metric space.

If $X$ satisfies all inequalities of negative type $(3, 1)$, if and only if it admits an isometric embedding into the product $r\cdot \mathbb{S}^1\times\RR^3$ for some $r>0$.

If $X$ satisfies all inequalities of negative type $(2, 2)$, if and only if it admits an isometric embedding into the product $Y\times\RR^3$, where $Y$ denotes the \emph{tripod};
that is, three half-lines with a common base point.
\end{thm}

Inequalities of negative type $(3, 1)$ hold in Alexandrov spaces with nonnegative curvature; it follows from the so-called Lang--Schroeder--Sturm inequality \cite{lang-schroeder, sturm}.
Similarly, inequalities of negative type $(2, 2)$ hold in Alexandrov spaces with nonpositive curvature.
This follows easily from the (2+2)-point comparison \cite[9.5]{AKP-2024}.
Since the tripod $Y$ has nonpositive curvature, and $\mathbb{S}^1$ has nonnegative curvature in the sense of Alexandrov, we get the following corollary, which also follows from the result of Abraham Wald \cite[§ 7]{wald}.

\begin{thm}{Corollary}\label{cor:Four-point arrays}
A 4-point metric space $X$ is isometric to a subset of a length space with nonnegative (nonpositive) curvature in the sense of Alexandrov if and only if all inequalities of negative type $(3, 1)$ (respectively, type $(2, 2)$) hold in $X$.
\end{thm}

The corresponding five-point versions of this corollary have been proved by Tetsu Toyoda \cite{toyoda,lebedeva-petrunin2021} and the first two authors \cite{lebedeva-petrunin-2024}, respectively.

\parit{Proof of \ref{prop:Four-point arrays}.}
Let us enumerate points in $X$ and let $\rho$ be the associated form on~$V_4$.

Choose a minimal form $\tilde\rho\le \rho$ such that all $(2,1)$-inequalities hold for $\tilde\rho$;
here $\tilde\rho\le \rho$ means that $\tilde\rho(v)\le \rho(v)$ for any vector $v$.
Consider the (semi)metric on $X$ with the associated form $\tilde\rho$;
denote the corresponding metric space by $\tilde X$.
If $X$ satisfies all inequalities of negative type $(3, 1)$ or $(2,2)$, then the same holds for $\tilde X$.

By \ref{obs:rank-one}, $X$ isometrically embeds into $\tilde X\times \RR^3$.
Hence it is sufficient to show that $\tilde X$ embeds into $Y$, or, respectively, into $r\cdot \mathbb{S}^1$ for some $r>0$.

Let $N\subset \mathbb{S}^2$ be a set where $\tilde\rho$ is negative and let $\bar N$ be its closure.
We can assume that $N$ is nonempty; otherwise,
$\rho\ge 0$ and by \ref{obs:rank-one}, the space $X$ is isometric to a 4-point subset of the Euclidean 3-space.

Since all $(2,1)$-inequalities hold for $\tilde\rho$, the form $\tilde\rho$
must be nonnegative on 4 equators $e_1,e_2,e_3,e_4$ in the directions of facets of $\triangle$.
Since $\tilde\rho$ is minimal, $\bar N$ has to touch $e_i$ at least at 3 directions (up to sign). 
If not, then there is a linear function, say $\sigma$, that vanishes at all common points of $\bar N$ and $e_i$ for all $i$.
In this case, consider the form $\tilde\rho-\eps\cdot \sigma^2$ for small $\eps>0$;
note that all $(2,1)$-inequalities still hold for this form.
Therefore, $\tilde\rho$ is not minimal --- a contradiction.

It means that $\bar N$ lies in a quadrangle or triangle, respectively, and touches its sides at three points or more.

In the case of a triangle, $\bar N$ has to touch all of its sides.
According to the diagram above, after relabeling, we can assume that
\begin{align*}
|x_1-x_2|&=|x_1-x_4|+|x_4-x_2|,
\\
|x_2-x_3|&=|x_2-x_4|+|x_4-x_3|,
\\
|x_3-x_1|&=|x_3-x_4|+|x_4-x_1|.
\end{align*}
In this case, the array can be embedded into the tripod $Y$.

In the case of a quadrangle, $\bar N$ touches at least three of its sides, but might touch all four.
Look at the diagram and convince yourself, that after relabeling, we may assume that
\begin{align*}
|x_1-x_4|&=|x_1-x_2|+|x_2-x_4|=|x_1-x_3|+|x_3-x_4|,
\\
|x_2-x_3|&=|x_2-x_4|+|x_4-x_3|.
\end{align*}
If it touches all sides, then in addition we have $|x_2-x_3|=|x_2-x_1|+|x_1-x_3|$.
In any case, the array can be embedded into $r\cdot \mathbb{S}^1$, where $r=|x_1-x_4|/\pi$;
so the points $x_1$ and $x_4$ are antipodal in $r\cdot \mathbb{S}^1$.
\qeds

The picture shows the possible positions of the set $N$.
\begin{figure}[h!]
\centering
\vskip-0mm
\includegraphics{mppics/pic-30}
\vskip-0mm
\end{figure}
Below it, we provide a diagram following the convention from \cite{lebedeva-petrunin-2010};
if three points, say $x_1$, $x_2$, and $x_3$, appear in that order on a smooth line, then $|x_1-x_2|+|x_2-x_3|=|x_1-x_3|$.

\section{Alexandrov's comparison}\label{Alexandrov's comparison}

\begin{thm}{Proposition}\label{prop:Alexandrov's comparison}
Suppose $K\subset W_4$ is defined by a single rank-one inequality on $4$-point arrays.
\begin{enumerate}[(i)]
\item If the inequality is of negative type $(2,2)$, then $\mathcal{M}_K$ consists of all length spaces with nonpositive curvature in the sense of Alexandrov.
\item \label{prop:Alexandrov's comparison:(3,1)} If the inequality is of negative type $(3,1)$, then $\mathcal{M}_K$ consists of all length spaces with nonnegative curvature in the sense of Alexandrov.
\item In the remaining cases, $\mathcal{M}_K$ consists of all length spaces.
\end{enumerate}

\end{thm}

This statement and Corollary~\ref{cor:Four-point arrays} imply that a single inequality of negative type $(2,2)$ or $(3,1)$ on a length space implies \emph{all} inequalities of the same type.

\parit{Proof.}
Our inequality can be written as 
\[\sum_{i,j}\lambda_i\cdot\lambda_j\cdot|x_i-x_j|_X^2\le 0,
\eqlbl{eq:lambda}
\]
where $\lambda_1+\lambda_2+\lambda_3+\lambda_4=0$.
If $\lambda_i=0$ for some $i$,
then the inequality follows from the triangle inequality.
This means that $\mathcal{M}_K$ consists of all length spaces.

It remains to consider the inequalities of negative type $(2,2)$ or $(3,1)$.
In these cases, we can assume that our $\lambda$-array is
\[(\alpha\cdot (1-\beta),\  (1-\alpha)\cdot(1-\beta),\  \beta,\ -1)\] 
for some $\alpha,\beta$ such that $0< \beta< 1$;
in case of $(2,2)$-inequality, we have $1<\alpha$, and in case of $(3,1)$-inequality, we have $0<\alpha<1$.

Consider the 4-point array $\bm{x}=(x_1,x_2,x_3,x_4)$  in the plane such that 
\[x_4=\alpha\cdot (1-\beta)\cdot x_1+(1-\alpha)\cdot(1-\beta)\cdot x_2+\beta\cdot x_3.\]
We can assume that the array matches one of the configurations in the pictures below,
so for $(3,1)$-inequality, point $x_4$ lies inside of the triangle $x_1x_2x_3$,
and for $(2,2)$-inequality the segment $[x_1x_3]$ intersects $[x_2x_4]$.

Note that we get equality in \ref{eq:lambda} for this array.
Moreover, this defines a bijection between plane $\bm{x}$-arrays up to affine transformation and $\lambda$-arrays up to multiplication by a nonzero coefficient;
as before, we assume that the $\bm{x}$-arrays are in general position --- no three of its points lie on one line.
Therefore one can describe our inequality by a 4-point array in general position.
If the points of the array lie at the vertices of a convex quadrangle,
then it corresponds to an inequality of type $(2,2)$.
If one of the points lies inside the triangle formed by the remaining points, then it corresponds to an inequality of type $(3,1)$.

\begin{figure}[ht!]
\vskip-0mm
\centering
\includegraphics{mppics/pic-10}
\vskip0mm
\end{figure}

Consider the affine transformation that sends $x_1\mapsto x_1$, $x_2\mapsto x_2$ and $x_3\z\mapsto x_4$;
suppose $x_4\mapsto x_5$.
Then
\begin{align*}
x_5&=\alpha\cdot (1-\beta)\cdot x_1+(1-\alpha)\cdot(1-\beta)\cdot x_2+\beta\cdot x_4=
\\
&=\alpha\cdot (1-\beta^2)\cdot x_1+(1-\alpha)\cdot(1-\beta^2)\cdot x_2+\beta^2\cdot x_3.
\end{align*}
Note that $x_4$ lies between $x_3$ and $x_5$;
in particular $|x_3-x_4|+|x_4-x_5|=|x_3-x_5|$.

\begin{thm}{Claim}\label{clm:1=>2}
Consider the inequalities of type \ref{eq:lambda} that correspond to the arrays $x_1,x_2,x_3,x_4$ and $x_1,x_2,x_3,x_5$;
let us call them first and second.

Suppose that the first inequality holds for any four-point array in a length space $X$.
Then the second inequality also holds.
\end{thm}

Indeed, passing to the ultracompletion, we may assume that $X$ is geodesic.
Choose 4 points $x_1,x_2,x_3,x_5\in X$ and let $x_4$ be a point on a geodesic $[x_3x_5]$ that divides it in the same ratio as in the 5-point configuration in the plane.
If we sum up the first inequality for arrays $x_1,x_2,x_3,x_4$ and $x_1,x_2,x_4,x_5$ with the appropriate coefficients, then we get the second inequality for $x_1,x_2,x_3,x_5$.

By the claim, the inequality for $\lambda$-array $(\alpha\cdot (1-\beta),(1-\alpha)\cdot(1\z-\beta), \beta,-1)$ implies the inequality for the $\lambda$-array $(\alpha\cdot (1-\beta^2), (1-\alpha)\cdot(1-\beta^2), \beta^2,-1)$.
Applying the claim several times, we get all the inequalities with $\lambda$-arrays
\[(\alpha\cdot (1-\gamma),\  (1-\alpha)\cdot(1-\gamma),\ \gamma,\ -1),\]
where $\gamma=\beta^{2^k}$ for an integer $k\ge 1$;
in particular, we get the following inequality
\[
\begin{aligned}
\alpha\cdot (1-\alpha)\cdot(1-\gamma)^2\cdot|x_1-x_2|^2 - \gamma\cdot |x_3-x_4|^2 &+
\\
+(1-\alpha)\cdot(1-\gamma)\cdot\gamma\cdot|x_2-x_3|^2-\alpha\cdot (1-\gamma)\cdot |x_1-x_4|^2&+
\\
+\alpha\cdot(1-\gamma)\cdot\gamma\cdot|x_1-x_3|^2-(1-\alpha)\cdot(1-\gamma)\cdot |x_2-x_4|^2&\le 0
\end{aligned}
\eqlbl{eq:lambda-inq}
\]
for arbitrarily small $\gamma>0$.

Choose $X\in \mathcal{M}_K$.
Let us apply \ref{eq:lambda-inq}
\begin{figure}[ht!]
\vskip-0mm
\centering
\includegraphics{mppics/pic-15}
\vskip0mm
\end{figure}
to a quadruple $x_1,x_2,x_3,x_4\in X$ such that $x_1$, $x_2$ and $x_4$ lie on one geodesic, and we have equality in the $(2,1)$-inequality with $\lambda$-array
\[(\alpha,\  (1-\alpha),\ 0,\ -1);\]
that is,
\[\alpha\cdot (1-\alpha)\cdot|x_1-x_2|^2-\alpha\cdot |x_1-x_4|^2-(1-\alpha)\cdot |x_2-x_4|^2=0.\eqlbl{eq:trig-inq}\]
%Then $\tfrac1\gamma\cdot($\ref{eq:lambda-inq}$\,-\,$\ref{eq:trig-inq}$)$ looks like \[\begin{aligned}-\alpha\cdot (1-\alpha)\cdot(2-\gamma)\cdot|x_1-x_2|^2 -  |x_3-x_4|^2 &+\\+(1-\alpha)\cdot(1-\gamma)\cdot|x_2-x_3|^2+\alpha\cdot|x_1-x_4|^2&+\\+\alpha\cdot(1-\gamma)\cdot|x_1-x_3|^2+(1-\alpha)\cdot |x_2-x_4|^2&\le 0.\end{aligned}\]
%Then \ref{eq:trig-inq}$\,+\,\tfrac1\gamma\cdot($\ref{eq:lambda-inq}$\,-\,$\ref{eq:trig-inq}$)$ looks like \[\begin{aligned}-\alpha\cdot (1-\alpha)\cdot(1-\gamma)\cdot|x_1-x_2|^2 -  |x_3-x_4|^2 &+\\+(1-\alpha)\cdot(1-\gamma)\cdot|x_2-x_3|^2&+\\+\alpha\cdot(1-\gamma)\cdot|x_1-x_3|^2&\le 0.\end{aligned}\]
%Since $\gamma>0$ can be taken arbitrary small, we get \[\begin{aligned}-2\cdot \alpha\cdot (1-\alpha)\cdot|x_1-x_2|^2 -  |x_3-x_4|^2 &+\\+(1-\alpha)\cdot|x_2-x_3|^2+\alpha\cdot|x_1-x_4|^2&+\\+\alpha\cdot|x_1-x_3|^2+(1-\alpha)\cdot |x_2-x_4|^2&\le 0.\end{aligned}\] Adding \ref{eq:trig-inq} to the last inequality, we get
Passing to the limit as $\gamma\to 0$ in the inequality \ref{eq:trig-inq}$\,+\,\tfrac1\gamma\cdot($\ref{eq:lambda-inq}$\,-\,$\ref{eq:trig-inq}$)$, we get
\[
\begin{aligned}
\alpha\cdot|x_1-x_3|^2+(1-\alpha)\cdot|x_2-x_3|^2-
\alpha\cdot (1-\alpha)\cdot|x_1-x_2|^2 \le |x_3-x_4|^2.\end{aligned}
\eqlbl{eq:CBB-CBA}
\]
%Passing to the limit as $\gamma\to 0$ in the inequality $2\cdot$\ref{eq:trig-inq}$\,+\,\tfrac1\gamma\cdot($\ref{eq:lambda-inq}$\,-\,$\ref{eq:trig-inq}$)$, we get \[ \begin{aligned} |x_3-x_4|^2&\ge (1-\alpha)\cdot|x_3-x_2|^2+\alpha\cdot x_3-x_1|^2- \\ &-(1-\alpha)\cdot |x_4-x_2|^2-\alpha\cdot|x_4-x_1|^2. \end{aligned} \eqlbl{eq:CBB-CBA'} \]
Nonnegative or nonpositive curvature in the sense of Alexandrov can be defined via this inequality for all $\alpha\in (0,1)$ and $\alpha\in (1,\infty)$, respectively; see \cite[8.14 and 9.14]{AKP-2024}.
So far, we have obtained it for only one value of $\alpha$;
however, applying iteration we can derive inequalities for the remaining values $\alpha\in (0,1)$ (respectfully, $\alpha\in (1,\infty)$).

More precisely, assume this inequality holds for some $\alpha\in (0,1)$, then we can change $\alpha$ to $(1-\alpha)$, $\alpha^2$,  $\alpha\cdot (1-\alpha)$, $(1-\alpha^2)$, and so on.
Together with any value $\xi$, this set contains $1-\xi$ and $\xi^k$ for any integer $k\ge 1$.
Observe that this set is dense in $(0,1)$.
Therefore, inequality \ref{eq:CBB-CBA} holds for any $\alpha\in (0,1)$.
This is equivalent to the point-on-side comparison for nonnegative curvature; see \cite[8.14]{AKP-2024}.
Similarly, one can show that if the inequality holds for some $\alpha>1$, then it holds for any $\alpha>1$,
and this is equivalent to the point-on-side comparison for nonpositive curvature; see \cite[9.14]{AKP-2024}.
\qeds

\section{Globalization}\label{par:globalization}

Let $K\subset W_n$ be a closed convex cone.
We say that a metric space $X$ meets \emph{local $K$-comparison} if any point $x\in X$ admits a neighborhood $U$ such that $K$-comparison holds for any $n$-point array in $U$.

If local $K$-comparison implies $K$-comparison for any length space, then we say that \emph{globalization holds} for $K$.

The following statement shows that if globalization holds for quadratic comparison, then it is either trivial or characterizes nonnegatively curved Alexandrov spaces;
so, Toponogov's theorem is the only nontrivial globalization theorem for quadratic conditions on 4-point arrays.

\begin{thm}{Theorem}\label{thm:globalization}
Suppose that the globalization holds for a closed convex cone $K\z\subset W_4$.
Assume that the $K$-comparison is not trivial;
that is, on one side $\mathcal{M}_K$ does not include all length spaces, and, on the other side, $\mathcal{M}_K$ contains a space with at least two distinct points.
Then $\mathcal{M}_K$ consists of Alexandrov spaces with nonnegative curvature.
\end{thm}

\begin{thm}{Lemma}\label{lem:globalization}
Under the assumptions of the theorem, $\mathcal{M}_K$ contains all Alexandrov spaces with nonnegative curvature.
\end{thm}

\parit{Proof.}
Since $K$-comparison is not trivial, $K\ne\{0\}$.
By \ref{prop:Associated form}, $\mathcal{M}_K$ contains the real line.
Therefore, local $K$-comparison holds
for any circle $r\cdot \mathbb{S}^1$ with $r>0$, and hence also for any product space $r\cdot \mathbb{S}^1\times\RR^3$.
It remains to apply \ref{prop:Four-point arrays}.
\qeds

In the following proof, we will use one statement from the next section.

\parit{Proof of the theorem.}
Let us denote by $K_0$ the cone in $W_4$ described by all inequalities of negative type $(3,1)$ and $(2,1)$.
By \ref{cor:Four-point arrays}, $K_0$ describes all metrics on 4-point arrays in Alexandrov spaces with nonnegative curvature.
By \ref{lem:globalization},  $K$~includes $K_0$.

Given $\delta>0$, consider all metrics with diameter at most $\delta$ on a 4-point array $\{x_1,x_2,x_3,x_4\}$ in an Alexandrov space with curvature at least $-1$.
Denote by $K_\delta\subset W_4$ the minimal closed convex cone that includes all associated forms of these metrics.
Note that $K_0\z\subset K_\delta$.
Furthermore, after rescaling the metric on $\{x_1,x_2,x_3,x_4\}$ with a factor of $\tfrac1\delta$, the array gets diameter at most $1$ and is embeddable in an Alexandrov space with curvature at least $-\delta^2$; therefore, $K_0=\bigcap_{\delta>0} K_\delta$ (see also Lemma~\ref{lem:area-bound}).

Every Riemannian manifold admits a local curvature bound at each point.
In particular, after appropriate rescaling, a small neighborhood of any point of a Riemannian manifold has curvature at least $-1$.
Therefore, any compact Riemannian manifold satisfies local $K_\delta$-comparison.

Suppose $K\supset K_\delta$ for some $\delta>0$.
Since globalization holds for $K$, the class $\mathcal{M}_K$ contains all compact Riemannian manifolds.
Every finite metric graph can be approximated by compact Riemannian manifolds;
to prove it,
realize the graph in Euclidean space with smooth edges of the same length and take the boundary of an appropriate neighborhood.
(A way stronger result is proved by Vedrin Šahović in his thesis \cite{sahovic2009}.)
Any metric on $\{x_1,x_2,x_3,x_4\}$ admits a distance-preserving embedding into a metric graph, so $K$ contains a form near the associated form for any semimetric on $\{x_1,x_2,x_3,x_4\}$.
Since $K$ is closed, it contains forms associated to all metrics on 4-point set;
so $K$ is defined only by the triangle inequalities, and the $K$-comparison is trivial.

From now on, we can assume that for any $\delta>0$ there is a form $\theta\in K_\delta\setminus K$.
By \ref{cor:squared-sides}, we can choose a $(3,1)$-inequality with the $\lambda$-array $(\lambda_1,\lambda_2,\lambda_3,-1)$ such that
\[\begin{aligned}
\sum_{i,j}&\lambda_i\cdot\lambda_j\cdot|x_i-x_j|_X^2
\le
\\
&\le
10\cdot\delta^2\cdot \lambda_1\cdot\lambda_2\cdot\lambda_3\cdot (|x_1-x_2|_X^2+|x_2-x_3|_X^2+|x_3-x_1|_X^2)
\end{aligned}
\eqlbl{eq:+squares}\]
for any 4-array $(x_1,x_2,x_3,x_4)$ with its form in $K$.

Let $\bm{\lambda}_\infty=(\lambda_1,\lambda_2,\lambda_3,-1)$ be a partial limit of $\lambda$-arrays of these inequalities;
that is, for some sequence $\delta_n\to 0^+$, we can choose corresponding inequalities of the form \ref{eq:+squares} with $\lambda$-arrays $\bm{\lambda}_n$ such that $\bm{\lambda}_n\to \bm{\lambda}_\infty$ as $n\to \infty$.
We have three options:
\begin{enumerate}[(i)]
\item\label{in} $\lambda_1>0$, $\lambda_2>0$, and $\lambda_3>0$;
\item\label{side} $\lambda_i=0$ for one index $i$;
\item\label{vertex} $\lambda_i=0$ for two indices $i$.
\end{enumerate}

In the first case,  $(\lambda_1,\lambda_2,\lambda_3,-1)$ defines an inequality of negative type $(3,1)$.
This inequality holds for any form in $K$.
Therefore, \ref{prop:Alexandrov's comparison}\ref{prop:Alexandrov's comparison:(3,1)} finishes the proof.

In case \ref{side}, we can assume that $\lambda_3=0$, so
\[\bm{\lambda}_\infty=(\alpha,(1-\alpha),0,-1);\]
it defines an inequality of negative type $(2,1)$.
Note that
\[\bm{\lambda}_n=(\alpha_n\cdot(1-\beta_n),(1-\alpha_n)\cdot(1-\beta_n),\beta_n,-1),\]
for some sequences $\alpha_n\to\alpha$ and $\beta_n\to 0^+$ as $n\to\infty$.
In the next paragraph we will show that the same calculations as in the proof of \ref{prop:Alexandrov's comparison} to these inequalities and passing to the limit, we get
\[
\alpha\cdot|x_1-x_3|^2+(1-\alpha)\cdot|x_2-x_3|^2-\alpha\cdot (1-\alpha)\cdot|x_1-x_2|^2
\le
|x_3-x_4|^2
\]
if $x_4$ lies on $[x_1x_2]$ and divides it in the ratio $(1-\alpha):\alpha$.
After that it remains to follow the end of proof of \ref{prop:Alexandrov's comparison}.

Indeed, suppose $x_4$ lies on $[x_1x_2]$ and divides it in the ratio $(1-\alpha_n):\alpha_n$, then
\[\alpha_n\cdot (1-\alpha_n)\cdot|x_1-x_2|^2-\alpha_n\cdot |x_1-x_4|^2-(1-\alpha_n)\cdot |x_2-x_4|^2=0;\leqno{\text{\ref{eq:trig-inq}}'}\]
this will be used instead of \ref{eq:trig-inq}.
If we assume $\alpha=\alpha_n$ and $\gamma=\beta_n$ in \ref{eq:lambda-inq}, then intead of zero in the right-hand side, we get the following error term:
\[E_n=10\cdot\delta_n^2\cdot \alpha_n\cdot (1-\alpha_n)\cdot(1-\beta_n)^2\cdot \beta_n\cdot(|x_1-x_2|_X^2+|x_2-x_3|_X^2+|x_3-x_1|_X^2);\]
let us label this inequality by  \ref{eq:lambda-inq}$'$.
The inequality \ref{eq:trig-inq}$'\,+\,\tfrac1\beta_n\cdot($\ref{eq:lambda-inq}$'\,-\,$\ref{eq:trig-inq}$')$ implies the following
\[
\begin{aligned}
\alpha_n\cdot|x_1-x_3|^2+(1-\alpha_n)\cdot|x_2-x_3|^2-
\alpha_n&\cdot (1-\alpha_n)\cdot|x_1-x_2|^2 \le
\\
&\le |x_3-x_4|^2 +  E_n/\beta_n+E_n.
\end{aligned}
\]
It remains to observe that the error term $E_n/\beta_n+E_n\to0$ as $n\to\infty$.

In case \ref{vertex}, we can assume that $\lambda_1=\lambda_2=0$, so $\bm{\lambda}_\infty=(0,0,1,-1)$ and
\[\bm{\lambda}_n=(\alpha_n\cdot(1-\beta_n),(1-\alpha_n)\cdot(1-\beta_n),\beta_n,-1),\]
where $0<\alpha_n<1$ and $\beta_n\to 1^-$ as $n\to\infty$.
Let us modify the corresponding inequalities defined by \ref{eq:+squares} to sweep $\bm{\lambda}_\infty$ out of the corner.
Namely, we have a sequence of $(3,1)$-inequalities with array
\[(\alpha_n\cdot(1-\beta_n),(1-\alpha_n)\cdot(1-\beta_n),\beta_n,-1)\]
that hold with error
\[10\cdot\delta_n^2\cdot\alpha_n\cdot(1-\beta_n)^2\cdot(1-\alpha_n)\cdot\beta_n \cdot (|x_1-x_2|_X^2+|x_2-x_3|_X^2+|x_3-x_1|_X^2).\]
Following the calculations in \ref{clm:1=>2}, we will use the same inequality several times for a sequence of point arrays.
By triangle inequality, we may assume that the error in the intermediate inequalities are at most
\[100\cdot\delta_n^2\cdot\alpha_n\cdot(1-\beta_n)^2\cdot(1-\alpha_n)\cdot\beta_n \cdot (|x_1-x_2|_X^2+|x_2-x_3|_X^2+|x_3-x_1|_X^2).\]
As a result we get an inequality with array
\[(\alpha_n\cdot(1-\beta_n^{2^k}),(1-\alpha_n)\cdot(1-\beta_n^{2^k}),\beta_n^{2^k},-1)\]
holds with an error
\[2^k\cdot100\cdot\delta_n^2\cdot\alpha_n\cdot(1-\beta_n)^2\cdot(1-\alpha_n)\cdot\beta_n \cdot (|x_1-x_2|_X^2+|x_2-x_3|_X^2+|x_3-x_1|_X^2).\]
Since $\beta_n\to 1^-$, we can choose $k=k(n)$ such that $k\to \infty$ as $n\to \infty$ and $\gamma^2\le \beta_n^{2^k}<\gamma$ for some fixed $0<\gamma<1$ and
\[
2^k\cdot\delta_n^2\cdot \alpha_n\cdot(1-\beta_n)^2\cdot(1-\alpha_n)\cdot\beta_n
<
\delta_n^2\cdot \alpha_n\cdot(1-\beta_n^{2^k})^2\cdot(1-\alpha_n)\cdot\beta_n^{2^k}
\]

That is, starting from a sequence of inequalities with $\lambda$-arrays converging to $(0,0,1,-1)$,
we have constructed another sequence of the same type with the limit $\lambda$-array covered in cases \ref{in} or \ref{side}.
\qeds

\section{Auxiliary statements}\label{Auxiliary statements}

\begin{thm}{Lemma}\label{lem:area-bound}
Let $(\lambda_1,\lambda_2,\lambda_3,-1)$ be the $\lambda$-array of an inequality of type $(3,1)$ and
let $(x_1$, $x_2$, $x_3$, $x_4)$ be a 4-point array in the hyperbolic space.

Then
\[\sum_{i,j=1}^4\lambda_i\cdot\lambda_j\cdot|x_i-x_j|_X^2
\le
(12+3\cdot\delta^2)\cdot\lambda_1\cdot\lambda_2\cdot\lambda_3\cdot\tilde a^2,\]
where $\tilde a$ denotes the area of model triangle $\tilde\triangle(x_1x_2x_3)_{\EE^2}$ and $\delta=\max\{|x_1-x_2|,|x_1-x_3|,|x_2-x_3|\}$.
\end{thm}

By Heron's formula,
\begin{align*}
16\cdot \tilde a^2
\quad=\quad &(|x_1-x_2|^2+|x_2-x_3|^2+|x_3-x_1|^2)^2
\\
-2\cdot &(|x_1-x_2|^4+|x_2-x_3|^4+|x_3-x_1|^4).
\end{align*}
In particular, $\tilde a^2$ is a quadratic form on $W_4$.

\parit{Proof.}
By the Kirszbraun theorem (see \cite{lang-schroeder,AKP-2011} or \cite[Chapter 10]{AKP-2024}), we may assume that $x_1$, $x_2$, $x_3$ and $x_4$ lie in the hyperbolic plane; moreover $x_4$ belongs to the solid hyperbolic triangle with vertices $x_1$, $x_2$ and $x_3$.
Denote by $a$ the area of this triangle.
Again, by the Kirszbraun theorem,
\[a\le \tilde a.\]

Since the hyperbolic plane has curvature $-1$, we have
\[\pi-\angk{x_1}{x_2}{x_3}_{\HH^2}-\angk{x_2}{x_3}{x_1}_{\HH^2}-\angk{x_3}{x_1}{x_2}_{\HH^2}=a.\]
These inequalities and the comparison implies that
\begin{align*}
0&\le \angk{x_1}{x_2}{x_3}_{\EE^2}-\angk{x_1}{x_2}{x_3}_{\HH^2}\le \tilde a.
\intertext{Since $x_4$ lies in the solid hyperbolic triangle with vertices $x_1$, $x_2$ and $x_3$, we also have $\angk{x_1}{x_2}{x_4}_{\HH^2}+\angk{x_1}{x_4}{x_3}_{\HH^2}=\angk{x_1}{x_2}{x_3}_{\HH^2}$. Hence, the comparison also implies}
0&\le
\angk{x_1}{x_2}{x_4}_{\EE^2}+\angk{x_1}{x_4}{x_3}_{\EE^2}-\angk{x_1}{x_2}{x_3}_{\HH^2}\le \tilde a.
\end{align*}

Set $\phi=\angk{x_1}{x_2}{x_3}_{\EE^2}$ and $\psi=\angk{x_1}{x_2}{x_4}_{\EE^2}+\angk{x_1}{x_4}{x_3}_{\EE^2}$.
From the above, we get $\phi\le \psi+\tilde a$.
By the law of cosines,
\[|x_2-x_3|^2=|x_1-x_2|^2+ |x_1-x_3|^2-2|x_1-x_2|\cdot|x_1-x_3|\cdot\cos\phi\]
Redefining the distance $|x_2-x_3|$ via the law of cosines with angle $\psi$,
\[|x_2-x_3|^2\mathrel{:=}|x_1-x_2|^2+ |x_1-x_3|^2-2|x_1-x_2|\cdot|x_1-x_3|\cdot\cos\psi\]
yields a Euclidean quadruple.
That is, decreasing $|x_2-x_3|^2$ by
\[s=2\cdot |x_1-x_2|\cdot|x_1-x_3|\cdot(\cos\psi-\cos\phi)\]
makes the quadruple Euclidean.
Since
\[\cos\psi-\cos\phi=\sin\phi\cdot\sin(\phi-\psi)-2\cdot\cos\phi\cdot (\sin\tfrac{\phi-\psi}2)^2,\] we get
\begin{align*}
s
&\le\
2\cdot|x_1-x_2|\cdot|x_1-x_3|\cdot (\tilde a\cdot\sin\phi+\tfrac12\cdot\tilde a^2)
\le
\\
&\le\ (4+\delta^2)\cdot \tilde a^2
\end{align*}

It follows that
\[\sum_{i,j}\lambda_i\cdot\lambda_j\cdot|x_i-x_j|_X^2\le \lambda_2\cdot\lambda_3\cdot(4+\delta^2)\cdot \tilde a^2,\]
We may assume that $\lambda_1\ge \lambda_2\ge \lambda_3>0$.
Since $\lambda_1+ \lambda_2+ \lambda_3=1$, we have $\lambda_1\ge \tfrac13$, and the statement follows.
\qeds

Recall that $K_0$ denotes the cone in $W_4$ described by all inequalities of negative type $(3,1)$ and $(2,1)$.

\begin{thm}{Corollary}\label{cor:squared-sides}
Let $K\subset W_4$ be a convex closed cone.
Suppose that $K\supset K_0$, but $K$-comparison does not hold for a 4-array of diameter at most $\delta$ in the hyperbolic space.
If $\delta$ is sufficiently small,
then there is an inequality of negative type $(3,1)$ with a $\lambda$-array $(\lambda_1,\lambda_2,\lambda_3,-1)$ such that the inequality
\[\sum_{i,j=1}^4\lambda_i\cdot\lambda_j\cdot|x_i-x_j|_X^2
\le
10\cdot\delta^2\cdot \lambda_1\cdot\lambda_2\cdot\lambda_3\cdot (|x_1-x_2|_X^2+|x_2-x_3|_X^2+|x_3-x_1|_X^2)\]
holds for any quadruple in $K$.
\end{thm}

This inequality should be interpreted as an $(3,1)$-inequality with a $\lambda$-array $(\lambda_1,\lambda_2,\lambda_3,-1)$ with error
\[10\cdot\delta^2\cdot \lambda_1\cdot\lambda_2\cdot\lambda_3\cdot (|x_1-x_2|_X^2+|x_2-x_3|_X^2+|x_3-x_1|_X^2).\]

\parit{Proof.}
Let $\theta$ be the associated form of the 4-array in the hyperbolic space.
Since $K$ is convex, we can choose a quadratic inequality that does not hold for $\theta$, but holds for any form in $K$.
Our inequality can be written as $\langle \omega,\rho_{\bm{x}} \rangle\ge 0$, where $\rho_{\bm{x}}\in W_4$ is an associated form of some 4-point array $(x_1,x_2,x_3,x_4)$ and $\omega$ is a fixed unit form in $W_4$.

\begin{wrapfigure}{o}{30mm}
\centering
\vskip-4mm
\includegraphics{mppics/pic-40}
\vskip-0mm
\end{wrapfigure}

Let $N\subset \SSS^2\subset V_4$ be the set of unit vectors $v$ such that $\theta(v)<0$.
The set $N$ does not intersect the four equators $e_1$, $e_2$, $e_3$, $e_4$ parallel to the facets of $\triangle$.
Moreover, since $K\supset K_0$, the set $N$ (up to sign) lies in one of triangles, say $T$;
we can assume that equators $e_1$, $e_2$, $e_3$ are extensions of sides of $T$, and $e_4$ is the remaining equator.

Since $K\supset K_0$, we have $\omega(v)\ge 0$ for any $v\in V_4$.
Let $\sigma$ be a unit 1-form on $V_4$ that vanishes on $e_4$.
By the spectral theorem, $\omega$ and $\sigma^2$ can be diagonalized in common basis (which does not have to be orthogonal).
Therefore,
\[\langle \omega,\rho_{\bm{x}}\rangle=\rho_{\bm{x}}(u)+\rho_{\bm{x}}(v)+\rho_{\bm{x}}(w)\eqlbl{eq:v_123}\]
for fixed vectors $u,v,w\in V_4$ such that $v$ and $w$ point in the direction of the equator $e_4$ or vanish;
the latter condition follows since $\sigma^2$ is also diagonalized.

The inequalities $\rho_{\bm{x}}(v)\ge 0$ and
$\rho_{\bm{x}}(w)\ge 0$ are of type $(2,1)$;
they follow from the triangle inequality, so we always have that $\rho_{\bm{x}}(v)\ge 0$ and
$\rho_{\bm{x}}(w)\ge 0$.
Moreover, the values $\rho_{\bm{x}}(v)$ and $\rho_{\bm{x}}(w)$ depend only on sides of triangle $[x_1x_2x_3]$.

Since
\[
\begin{aligned}
\langle\omega,\theta\rangle=\theta(u)+\theta(v)+\theta(w)&<0,
&
\theta(v)&\ge0,
&\text{and}&&
\theta(w)&\ge0,
\end{aligned}
\eqlbl{eq:uvw}
\]
we have that $u$ points in a direction of $N$.
Therefore, $\rho_{\bm{x}}(u)\ge0$ is an inequality of negative type $(3,1)$.

Suppose that the array $\bm{x}=(x_1,x_2,x_3,x_4)$ is equipped with a metric such that its associated form is $\theta$.
Let us rescale $u$, $v$, and $w$ so that the inequality $\theta(u)\ge 0$ (which as we know has negative type $(3,1)$)
has $\lambda$-array $(\lambda_1,\lambda_2,\lambda_3,-1)$.
Since $\delta$ is small, \ref{eq:uvw} and \ref{lem:area-bound} imply that
\[\theta(v)+\theta(w)
\le
13\cdot\lambda_1\cdot\lambda_2\cdot\lambda_3\cdot\tilde a^2.\]

For general array $\bm{x}=(x_1,x_2,x_3,x_4)$, we have
\[\rho_{\bm{x}}(v)=\eps_v\cdot \tilde d_v^2
\quad\text{and}\quad
 \rho_{\bm{x}}(w)=\eps_w\cdot \tilde d_w^2,
\]
where
$\tilde d_v$ and $\tilde d_w$ are distances from a vertex of the model triangle $\tilde\triangle(x_1x_2x_3)_{\EE^2}$ to a point on the opposite side that divides it in a certain ratio and $\eps_v,\eps_w\ge 0$.

In particular, for our choice of $\bm{x}$ it implies $\theta(v)=\eps_v\cdot \tilde d_v^2$ and $\theta(w)=\eps_w\cdot \tilde d_w^2$
Since the diameter of $\tilde\triangle(x_1x_2x_3)$ is at most $\delta$, we have
$\tilde a\le \delta\cdot \tilde d_v/2$ and
$\tilde a\le \delta\cdot \tilde d_w/2$.
Hence
\[\eps_v+\eps_w\le \tfrac{13}4\cdot \delta^2\cdot\lambda_1\cdot\lambda_2\cdot\lambda_3.\]

Note that for general 4-point array, $\tilde d_v$ and $\tilde d_w$ do not exceed the maximal side of the triangle $x_1x_2x_3$ --- hence the result.
\qeds

\section{Remarks}

The requirement made in \ref{thm:globalization} that the cone $K$ is closed is necessary;
without it, the globalization holds for the cone described by the inequality
\[|x_1-x_2|^2+|x_1-x_3|^2+|x_2-x_3|^2<4\cdot(|x_1-x_4|^2+|x_2-x_4|^2+|x_3-x_4|^2),\]
assuming that the right-hand side is positive.
To verify this statement, note that the inequality forbids tripods.

It would be super-nice to find a quadratic inequality for $n$-point arrays with globalization that is not implied by the standard globalization theorem.
Some candidates can be found in our earlier paper \cite{lebedeva-petrunin-zolotov}.
Also, it might be possible to prove a version of our globalization theorem
for simply connected spaces, which includes the Cartan--Hadamard theorem.

For general (closed) conditions on semimetrics on $n$-point arrays, globalization holds of course for curvature bounded below by $\kappa\in \RR$ in the sense of Alexandrov,
but it holds for other conditions as well;
the set of semimetrics on $4$-point arrays that are embeddable in $r\cdot\SSS^1$ for any $r>0$ gives an example.
Therefore, understanding globalization phenomena in such general settings is even more interesting.

{\sloppy
\def\emph{\textit}
\printbibliography[heading=bibintoc]
\fussy
}

\end{document}
